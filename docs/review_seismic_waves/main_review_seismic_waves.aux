\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{unsrtnat}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{Seriani2020}
\citation{Seriani2020}
\citation{Moczo,virieux_review_2011,Igel2017,komatitsch_introduction_1999,chaljub_spectral-element_2007}
\citation{Moczo,virieux_review_2011,Igel2017,komatitsch_introduction_1999,chaljub_spectral-element_2007}
\HyPL@Entry{0<</S/D>>}
\citation{abadi_tensorflow_2016,paszke_pytorch_2019,jax2018github}
\citation{abadi_tensorflow_2016,paszke_pytorch_2019,jax2018github}
\citation{paszke_automatic_2017,baydin_automatic_2017}
\citation{paszke_automatic_2017,baydin_automatic_2017}
\citation{barron_universal_1993}
\citation{barron_universal_1993}
\citation{cuomo_scientific_2022,karniadakis_physics-informed_2021}
\citation{cuomo_scientific_2022,karniadakis_physics-informed_2021}
\citation{vadyala_review_2022,deng_physics-informed_2023,lino_current_2023}
\citation{vadyala_review_2022,deng_physics-informed_2023,lino_current_2023}
\citation{jingbo_research_2023}
\citation{jingbo_research_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The growth of literature related to machine learning and wave propagation modeling. Number of publications according to Scopus between 2010 and 2023. The implemented query was: "machine learning" OR "deep learning" OR "neural networks" AND "wave propagation" OR "wave equation" AND (modeling OR modelling OR model OR simulation) AND (PUBYEAR > 2009 AND PUBYEAR < 2024).\relax }}{2}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:publications_absolute_relative}{{1}{2}{The growth of literature related to machine learning and wave propagation modeling. Number of publications according to Scopus between 2010 and 2023. The implemented query was: "machine learning" OR "deep learning" OR "neural networks" AND "wave propagation" OR "wave equation" AND (modeling OR modelling OR model OR simulation) AND (PUBYEAR > 2009 AND PUBYEAR < 2024).\relax }{figure.caption.2}{}}
\citation{Tarantola}
\citation{Tarantola}
\citation{galiounas_battery_2022,ren_seismicnet_2024,mccann_convolutional_2017}
\citation{galiounas_battery_2022,ren_seismicnet_2024,mccann_convolutional_2017}
\citation{moseley_physics-informed_2022,alkhadhr_wave_2023}
\citation{moseley_physics-informed_2022,alkhadhr_wave_2023}
\citation{Carcione2002}
\citation{Carcione2002}
\@writefile{toc}{\contentsline {section}{\numberline {1}Modeling of Wave Propagation}{3}{section.1}\protected@file@percent }
\newlabel{sec:modeling_wave_propagation}{{1}{3}{Modeling of Wave Propagation}{section.1}{}}
\newlabel{eq:pde}{{1}{3}{Modeling of Wave Propagation}{section.1}{}}
\newlabel{acoustic}{{1}{3}{Modeling of Wave Propagation}{figure.caption.3}{}}
\citation{moseley_fast_2018,lehmann_fourier_2023}
\citation{moseley_fast_2018,lehmann_fourier_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Scheme of the forward and inverse problems encountered in solving partial differential equations (PDEs). In the forward scenario, the inputs $(x,t;c)$ are employed to characterize a model across PDEs. Subsequently, the PDEs are resolved through either standard numerical methods (SNM) or neural networks based methods (MLBM) to derive a solution $u$. Standard numerical methods such as: finite differences (FD), finite elements (FE), pseudo-spectral (PS), finite volumes (FV), and spectral elements (SE). Also, deep learning techniques include, for example, Physics Informed Neural Networks (PINNs), Neural Operator (NO), and Neural Networks (NN). In the case of the inverse problem, the objective is to determine the parameters, for example, the wave speed, $c$ starting from the solution $u$.\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:forward_inverse}{{2}{4}{Scheme of the forward and inverse problems encountered in solving partial differential equations (PDEs). In the forward scenario, the inputs $(x,t;c)$ are employed to characterize a model across PDEs. Subsequently, the PDEs are resolved through either standard numerical methods (SNM) or neural networks based methods (MLBM) to derive a solution $u$. Standard numerical methods such as: finite differences (FD), finite elements (FE), pseudo-spectral (PS), finite volumes (FV), and spectral elements (SE). Also, deep learning techniques include, for example, Physics Informed Neural Networks (PINNs), Neural Operator (NO), and Neural Networks (NN). In the case of the inverse problem, the objective is to determine the parameters, for example, the wave speed, $c$ starting from the solution $u$.\relax }{figure.caption.3}{}}
\newlabel{elastic}{{1}{4}{Modeling of Wave Propagation}{figure.caption.3}{}}
\newlabel{viscoelastic}{{1}{4}{Modeling of Wave Propagation}{figure.caption.3}{}}
\newlabel{anisotropic}{{1}{4}{Modeling of Wave Propagation}{figure.caption.3}{}}
\citation{Moczo2014}
\citation{Moczo2014}
\citation{madariaga_dynamics_1976,Virieux1986}
\citation{madariaga_dynamics_1976,Virieux1986}
\citation{Zhou2021}
\citation{Zhou2021}
\citation{liu_simulation_2023}
\citation{liu_simulation_2023}
\citation{FEniCS,sander_dune_2020}
\citation{FEniCS,sander_dune_2020}
\citation{dimitri_komatitsch_2023_10415228,komatitsch_2024_10823181}
\citation{dimitri_komatitsch_2023_10415228,komatitsch_2024_10823181}
\citation{komatitsch_unsplit_2007}
\citation{komatitsch_unsplit_2007}
\citation{saloma_computational_1993}
\citation{saloma_computational_1993}
\newlabel{nonlinear}{{1}{5}{Modeling of Wave Propagation}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Standard Numerical Methods}{5}{section.2}\protected@file@percent }
\newlabel{sec:standard_numerical_methods}{{2}{5}{Standard Numerical Methods}{section.2}{}}
\citation{hornik_approximation_1991}
\citation{hornik_approximation_1991}
\citation{lecun_deep_2015,goodfellow_deep_2016}
\citation{lecun_deep_2015,goodfellow_deep_2016}
\citation{blechschmidt_three_2021}
\citation{blechschmidt_three_2021}
\citation{li_neural_2020,li_fourier_2021}
\citation{li_neural_2020,li_fourier_2021}
\@writefile{toc}{\contentsline {section}{\numberline {3}Machine learning Methods}{6}{section.3}\protected@file@percent }
\newlabel{sec:machine_learning_methods}{{3}{6}{Machine learning Methods}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Artificial Intelligence subsets. (A) Deep learning as a subset of machine learning and artificial intelligence and (B) basic architecture of artificial neural networks.\relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{deep_learning_subset_architecture}{{3}{6}{Artificial Intelligence subsets. (A) Deep learning as a subset of machine learning and artificial intelligence and (B) basic architecture of artificial neural networks.\relax }{figure.caption.4}{}}
\citation{raissi_hidden_2018}
\citation{raissi_hidden_2018}
\citation{raissi_numerical_2018}
\citation{raissi_numerical_2018}
\citation{Raissi2019}
\citation{Raissi2019}
\citation{lagaris_artificial_1998}
\citation{lagaris_artificial_1998}
\citation{karniadakis_physics-informed_2021}
\citation{karniadakis_physics-informed_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Physics-informed neural networks scheme applied to the wave equation.\relax }}{7}{figure.caption.5}\protected@file@percent }
\newlabel{deep_learning_subset_architecture}{{4}{7}{Physics-informed neural networks scheme applied to the wave equation.\relax }{figure.caption.5}{}}
\citation{blechschmidt_three_2021}
\citation{blechschmidt_three_2021}
\citation{lehmann_fourier_2023}
\citation{lehmann_fourier_2023}
\citation{mcgreivy_weak_2024}
\citation{kharazmi_variational_2019}
\citation{kharazmi_variational_2019}
\citation{chen2020neurodiffeq}
\citation{chen2020neurodiffeq}
\citation{lu2021deepxde}
\citation{lu2021deepxde}
\citation{https://doi.org/10.48550/arxiv.2107.09443}
\citation{https://doi.org/10.48550/arxiv.2107.09443}
\citation{bafghi_pinns-torch_2023}
\citation{bafghi_pinns-torch_2023}
\@writefile{toc}{\contentsline {section}{\numberline {4}Applications}{9}{section.4}\protected@file@percent }
\newlabel{sec:applications}{{4}{9}{Applications}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Search flowchart and number of publications after each step. During the systematic review process, Scopus and Google Scholar were utilized with the relevant search terms (i), and the research was restricted to works in English and within the time frame of 2013-2024 (ii). The resulting lists were then sorted by relevance and limited to a maximum of 50 entries, with duplicates removed (iii). Finally (iv), a manual filter was applied by reading the titles and abstracts to ensure the publications were pertinent to our chosen field.\relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig:scheme_systematic_review}{{5}{9}{Search flowchart and number of publications after each step. During the systematic review process, Scopus and Google Scholar were utilized with the relevant search terms (i), and the research was restricted to works in English and within the time frame of 2013-2024 (ii). The resulting lists were then sorted by relevance and limited to a maximum of 50 entries, with duplicates removed (iii). Finally (iv), a manual filter was applied by reading the titles and abstracts to ensure the publications were pertinent to our chosen field.\relax }{figure.caption.6}{}}
\citation{karimpouli_physics_2020}
\citation{karimpouli_physics_2020}
\citation{Song2022}
\citation{Song2022}
\citation{rash_2022}
\citation{rash_2022}
\citation{moseley_physics-informed_2022}
\citation{moseley_physics-informed_2022}
\citation{ren_seismicnet_2024}
\citation{ren_seismicnet_2024}
\bibdata{refs}
\bibcite{Seriani2020}{{1}{2020}{{Seriani and Oliveira}}{{}}}
\bibcite{Moczo}{{2}{2007}{{Moczo et~al.}}{{Moczo, Robertsson, and Eisner}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{10}{section.5}\protected@file@percent }
\newlabel{sec:conclusions}{{5}{10}{Conclusions}{section.5}{}}
\bibcite{virieux_review_2011}{{3}{2011}{{Virieux et~al.}}{{Virieux, Calandra, and Plessix}}}
\bibcite{Igel2017}{{4}{2017}{{Igel}}{{}}}
\bibcite{komatitsch_introduction_1999}{{5}{1999}{{Komatitsch and Tromp}}{{}}}
\bibcite{chaljub_spectral-element_2007}{{6}{2007}{{Chaljub et~al.}}{{Chaljub, Komatitsch, Vilotte, Capdeville, Valette, and Festa}}}
\bibcite{abadi_tensorflow_2016}{{7}{2016}{{Abadi et~al.}}{{Abadi, Barham, Chen, Chen, Davis, Dean, Devin, Ghemawat, Irving, Isard, Kudlur, Levenberg, Monga, Moore, Murray, Steiner, Tucker, Vasudevan, Warden, Wicke, Yu, and Zheng}}}
\bibcite{paszke_pytorch_2019}{{8}{2019}{{Paszke et~al.}}{{Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison, Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala}}}
\bibcite{jax2018github}{{9}{2018}{{Bradbury et~al.}}{{Bradbury, Frostig, Hawkins, Johnson, Leary, Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and Zhang}}}
\bibcite{paszke_automatic_2017}{{10}{2017}{{Paszke et~al.}}{{Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin, Desmaison, Antiga, and Lerer}}}
\bibcite{baydin_automatic_2017}{{11}{2017}{{Baydin et~al.}}{{Baydin, Pearlmutter, Radul, and Siskind}}}
\bibcite{barron_universal_1993}{{12}{1993}{{Barron}}{{}}}
\bibcite{cuomo_scientific_2022}{{13}{2022}{{Cuomo et~al.}}{{Cuomo, Di~Cola, Giampaolo, Rozza, Raissi, and Piccialli}}}
\bibcite{karniadakis_physics-informed_2021}{{14}{2021}{{Karniadakis et~al.}}{{Karniadakis, Kevrekidis, Lu, Perdikaris, Wang, and Yang}}}
\bibcite{vadyala_review_2022}{{15}{2022}{{Vadyala et~al.}}{{Vadyala, Betgeri, Matthews, and Matthews}}}
\bibcite{deng_physics-informed_2023}{{16}{2023}{{Deng et~al.}}{{Deng, Nguyen, Medjaher, Gogu, and Morio}}}
\bibcite{lino_current_2023}{{17}{2023}{{Lino et~al.}}{{Lino, Fotiadis, Bharath, and Cantwell}}}
\bibcite{jingbo_research_2023}{{18}{2023}{{JingBo et~al.}}{{JingBo, Cai, and PengFei}}}
\bibcite{Tarantola}{{19}{2005}{{Tarantola}}{{}}}
\bibcite{galiounas_battery_2022}{{20}{2022}{{Galiounas et~al.}}{{Galiounas, Tranter, Owen, Robinson, Shearing, and Brett}}}
\bibcite{ren_seismicnet_2024}{{21}{2024}{{Ren et~al.}}{{Ren, Rao, Chen, Wang, Sun, and Liu}}}
\bibcite{mccann_convolutional_2017}{{22}{2017}{{McCann et~al.}}{{McCann, Jin, and Unser}}}
\bibcite{moseley_physics-informed_2022}{{23}{2022}{{Moseley}}{{}}}
\bibcite{alkhadhr_wave_2023}{{24}{2023}{{Alkhadhr and Almekkawy}}{{}}}
\bibcite{Carcione2002}{{25}{2002}{{Carcione}}{{}}}
\bibcite{moseley_fast_2018}{{26}{2018}{{Moseley et~al.}}{{Moseley, Markham, and Nissen-Meyer}}}
\bibcite{lehmann_fourier_2023}{{27}{2023}{{Lehmann et~al.}}{{Lehmann, Gatti, Bertin, and Clouteau}}}
\bibcite{Moczo2014}{{28}{2014}{{Moczo et~al.}}{{Moczo, Kristek, and Gális}}}
\bibcite{madariaga_dynamics_1976}{{29}{1976}{{Madariaga}}{{}}}
\bibcite{Virieux1986}{{30}{1986}{{Virieux}}{{}}}
\bibcite{Zhou2021}{{31}{2021}{{Zhou et~al.}}{{Zhou, Liu, and Wang}}}
\bibcite{liu_simulation_2023}{{32}{2023}{{Liu et~al.}}{{Liu, Zhou, and Zeng}}}
\bibcite{FEniCS}{{33}{2016}{{Langtangen and Logg}}{{}}}
\bibcite{sander_dune_2020}{{34}{2020}{{Sander}}{{}}}
\bibcite{dimitri_komatitsch_2023_10415228}{{35}{2023}{{Komatitsch et~al.}}{{Komatitsch, Tromp, Gharti, Peter, Cano, Bachmann, Bottero, Brissaud, Chow, Cristini, Cui, Gassmoeller, Gineste, Halpaap, Heien, Labarta, Lefebvre, Goff, Loher, Liu, Liu, Liu, Liu, Luet, Martin, Matzen, Modrak, Morency, Nagaso, Rosenkrantz, Rusmanugroho, de~Andrade, Tape, Vilotte, Xie, and Zhang}}}
\bibcite{komatitsch_2024_10823181}{{36}{2024}{{Komatitsch et~al.}}{{Komatitsch, Tromp, Garg, Gharti, Nagaso, Oral, Peter, Afanasiev, Almada, Ampuero, Bachmann, Bai, Basini, Beller, Bishop, Bissey, Blitz, Bottero, Bozdag, Casarotti, Charles, Chen, Cristini, Durochat, Galvez~Barron, Gassmoeller, Goeddeke, Grinberg, Gupta, Heien, Hjoerleifsdottir, Karakostas, Kientz, Labarta, Le~Goff, Le~Loher, Lefebvre, Liu, Liu, Luet, Luo, Maggi, Magnoni, Martin, Matzen, McBain, McRitchie, Meschede, Messmer, Michea, Miller, Modrak, Monteiller, Morency, Nadh~Somala, Nissen-Meyer, Pouget, Rietmann, Sales~de Andrade, Savage, Schuberth, Sieminski, Smith, Strand, Tape, Valero~Cano, Videau, Vilotte, Weng, Xie, Zhang, and Zhu}}}
\bibcite{komatitsch_unsplit_2007}{{37}{2007}{{Komatitsch and Martin}}{{}}}
\bibcite{saloma_computational_1993}{{38}{1993}{{Saloma}}{{}}}
\bibcite{hornik_approximation_1991}{{39}{1991}{{Hornik}}{{}}}
\bibcite{lecun_deep_2015}{{40}{2015}{{LeCun et~al.}}{{LeCun, Bengio, and Hinton}}}
\bibcite{goodfellow_deep_2016}{{41}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, and Courville}}}
\bibcite{blechschmidt_three_2021}{{42}{2021}{{Blechschmidt and Ernst}}{{}}}
\bibcite{li_neural_2020}{{43}{2020}{{Li et~al.}}{{Li, Kovachki, Azizzadenesheli, Liu, Bhattacharya, Stuart, and Anandkumar}}}
\bibcite{li_fourier_2021}{{44}{2021}{{Li et~al.}}{{Li, Kovachki, Azizzadenesheli, Liu, Bhattacharya, Stuart, and Anandkumar}}}
\bibcite{raissi_hidden_2018}{{45}{2018}{{Raissi and Karniadakis}}{{}}}
\bibcite{raissi_numerical_2018}{{46}{2018}{{Raissi et~al.}}{{Raissi, Perdikaris, and Karniadakis}}}
\bibcite{Raissi2019}{{47}{2019}{{Raissi et~al.}}{{Raissi, Perdikaris, and Karniadakis}}}
\bibcite{lagaris_artificial_1998}{{48}{1998}{{Lagaris et~al.}}{{Lagaris, Likas, and Fotiadis}}}
\bibcite{mcgreivy_weak_2024}{{49}{2024}{{McGreivy and Hakim}}{{}}}
\bibcite{kharazmi_variational_2019}{{50}{2019}{{Kharazmi et~al.}}{{Kharazmi, Zhang, and Karniadakis}}}
\bibcite{chen2020neurodiffeq}{{51}{2020}{{Chen et~al.}}{{Chen, Sondak, Protopapas, Mattheakis, Liu, Agarwal, and Di~Giovanni}}}
\bibcite{lu2021deepxde}{{52}{2021}{{Lu et~al.}}{{Lu, Meng, Mao, and Karniadakis}}}
\bibcite{https://doi.org/10.48550/arxiv.2107.09443}{{53}{2021}{{Zubov et~al.}}{{Zubov, McCarthy, Ma, Calisto, Pagliarino, Azeglio, Bottero, Luján, Sulzer, Bharambe, Vinchhi, Balakrishnan, Upadhyay, and Rackauckas}}}
\bibcite{bafghi_pinns-torch_2023}{{54}{2023}{{Bafghi and Raissi}}{{}}}
\bibcite{karimpouli_physics_2020}{{55}{2020}{{Karimpouli and Tahmasebi}}{{}}}
\bibcite{Song2022}{{56}{2022}{{Song and Alkhalifah}}{{}}}
\bibcite{rash_2022}{{57}{2022}{{Rasht-Behesht et~al.}}{{Rasht-Behesht, Huber, Shukla, and Karniadakis}}}
\gdef \@abspage@last{16}
